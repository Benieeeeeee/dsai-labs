{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e39257b0",
   "metadata": {},
   "source": [
    "# Module 1. Samples\n",
    "\n",
    "## Getting Started with Jupyter Notebooks\n",
    "\n",
    "Jupyter Notebooks (or iPython Notebooks) are files with a mixture of Markdown and Python code. It's a very convenient format so we'll be using this quite a lot during this course!\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "To get started, it is not necessary to install software on your laptop. [Google Colab](https://colab.research.google.com/) is a free online iPython development environment, but it does require a Google account in order to use it. You can create a local clone of the Github repo with the lab assignments and upload the Notebook files you want to work with to Colab.\n",
    "\n",
    "Remark that the Google Colab environment has older versions installed of the Python libraries that we will be using throughout this course. Usually, that's not a problem, but sometimes you will run into errors, e.g. because some parameter in our Python code didn't exist yet in that version. The solution is to add a new code block at the beginning of your Notebook file with content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dfa18",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/benro/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade matplotlib\n",
    "%pip install --upgrade scipy\n",
    "%pip install --upgrade statsmodels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45eea59b",
   "metadata": {},
   "source": [
    "You only have to do this in Notebooks where you encounter errors, and only for the libraries that cause these errors. The installation may take a while and you need to restart the Python runtime afterwards by clicking the button that appears.\n",
    "\n",
    "### Local environment\n",
    "\n",
    "If you prefer to have a local development environment, you need to install Python and Visual Studio Code with the necessary extensions for working with Python (e.g. Pylance, Jupyter, Jupyter Keymap, etc.) The first time you open a Notebook file, VSCode will offer you to install these extensions.\n",
    "\n",
    "To install Python and VSCode on Windows, we recommend using `winget`. First, check the latest version of Python on the [Python website](https://www.python.org/downloads/windows/). For example, at the time of writing, the latest version was 3.12.2. We'll need to specify the major and minor version (e.g. 3.12) when installing. Then, open a PowerShell or command prompt as Administrator and run:\n",
    "\n",
    "```console\n",
    "> winget install Microsoft.VisualStudioCode\n",
    "> winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "Remark that `winget upgrade --all` will install maintenance releases of Python, but it will not upgrade to a new major or minor version.\n",
    "\n",
    "Most Python scripts (or Jupyter Notebooks) for analyzing data use the same program libraries. The most important ones are:\n",
    "\n",
    "- `numpy` - multidimensional arrays, linear algebra, etc.\n",
    "- `scipy` - mathematics, science, engineering etc.\n",
    "- `pandas` - data-analysis and -manipulation\n",
    "- `matplotlib`, `seaborn` - data visualisation\n",
    "- `scikit-learn` - regression and machine learning\n",
    "\n",
    "You can install these using `pip`:\n",
    "\n",
    "```console\n",
    "> pip install matplotlib numpy pandas scipy seaborn scikit-learn statsmodels\n",
    "```\n",
    "\n",
    "Or, alteratively, by executing the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e108c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.0-cp311-cp311-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.5 kB ? eta -:--:--\n",
      "     ------------------- ------------------- 81.9/165.5 kB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 165.5/165.5 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting numpy>=1.23 (from matplotlib)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/8.0 MB 12.8 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.6/8.0 MB 7.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.2/8.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.6/8.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.1/8.0 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.6/8.0 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.0/8.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.5/8.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.6/8.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.9/8.0 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.4/8.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.8/8.0 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.3/8.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.7/8.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.2/8.0 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.6/8.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/8.0 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.6/8.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp311-cp311-win_amd64.whl (188 kB)\n",
      "   ---------------------------------------- 0.0/188.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 188.2/188.2 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB ? eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.8 MB 9.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/15.8 MB 9.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.8/15.8 MB 10.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.2/15.8 MB 10.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.1/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.6/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.4/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.9/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.3/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.2/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.0/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.4/2.5 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.9/2.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.5 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.9/2.5 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.2/103.2 kB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0 kiwisolver-1.4.5 matplotlib-3.9.0 numpy-1.26.4 pillow-10.3.0 pyparsing-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/11.6 MB 6.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/11.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 10.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/11.6 MB 10.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.6 MB 10.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.9/11.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.9/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.4/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.4/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.9/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.4/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.9/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.4/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.0/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.5/11.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.0/11.6 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.5/11.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.6 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   --------------------------------- ----- 440.3/505.5 kB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 505.5/505.5 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.6 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.6/60.6 kB 811.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/46.2 MB 6.5 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.7/46.2 MB 8.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.4/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.9/46.2 MB 10.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.4/46.2 MB 10.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.9/46.2 MB 10.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.4/46.2 MB 10.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.9/46.2 MB 10.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.4/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.9/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.4/46.2 MB 10.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.9/46.2 MB 10.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.5/46.2 MB 10.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.0/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.5/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.8/46.2 MB 10.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.3/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.8/46.2 MB 10.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 9.2/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.6/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 10.0/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 10.3/46.2 MB 10.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.8/46.2 MB 10.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.2/46.2 MB 10.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.6/46.2 MB 10.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.9/46.2 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 12.4/46.2 MB 9.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.9/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.9/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.3/46.2 MB 9.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.8/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.2/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.7/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.2/46.2 MB 9.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.6/46.2 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 17.1/46.2 MB 9.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 17.6/46.2 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 18.0/46.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.5/46.2 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.0/46.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.6/46.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.1/46.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.6/46.2 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.1/46.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.6/46.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.1/46.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.6/46.2 MB 10.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.1/46.2 MB 10.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.6/46.2 MB 10.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 24.1/46.2 MB 10.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.7/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 25.2/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.7/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.7/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.3/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.8/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.3/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.8/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.3/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.8/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.3/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.8/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.3/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.8/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.3/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.8/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 33.4/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.9/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.4/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.9/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 35.4/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.9/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.4/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.9/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.4/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.9/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.5/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 39.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.5/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.5/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.5/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.5/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.0/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.5/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.5/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 10.4 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 276.5/294.9 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.9/294.9 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 7.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/11.0 MB 8.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 8.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.0/11.0 MB 9.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.5/11.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.5/11.0 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.1/11.0 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.6/11.0 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/11.0 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (2.2.2)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in c:\\users\\benro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB 660.6 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.2/9.9 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/9.9 MB 5.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/9.9 MB 7.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.9 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/9.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.3/9.9 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/9.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/9.9 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.8/9.9 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.3/9.9 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.4/9.9 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.9/9.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.4/9.9 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.9 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.5/9.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/9.9 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.5/9.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.9/233.9 kB 14.0 MB/s eta 0:00:00\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scipy\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf2e22",
   "metadata": {},
   "source": [
    "\n",
    "Since you usually need the same packages every time, it is best to put them at the top of every script or Notebook file you write. By convention, package names are often abbreviated in a consistent manner, e.g. `np` for `numpy`, `sns` for `seaborn`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5195c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import numpy as np                                  # \"Scientific computing\"\n",
    "import scipy.stats as stats                         # Statistical tests\n",
    "\n",
    "import pandas as pd                                 # Data Frame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import matplotlib.pyplot as plt                     # Basic visualisation\n",
    "from statsmodels.graphics.mosaicplot import mosaic  # Mosaic diagram\n",
    "import seaborn as sns                               # Advanced data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddffd8",
   "metadata": {},
   "source": [
    "## Opening a Dataset, General Information\n",
    "\n",
    "You can read in a dataset from a variety of sources (Rajagopalan, 2021, p.158). You can specify a path to a file or even a URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192d66fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the Titanic dataset. (Rajagopalan, 2021, p. 106)\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/DataRepo2019/Data-files/master/titanic.csv')\n",
    "# Show the first few records of the Data Frame\n",
    "titanic.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e377baca",
   "metadata": {},
   "source": [
    "If you want to open a dataset that you stored on Google Drive (where Google Colab stores all your Notebooks), you can use the following code instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "556425a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure your Google Drive is accessible from within the notebook\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the dataset from your Google Drive (here, we stored it in a subfolder\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# called \"data\")\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Ensure your Google Drive is accessible from within the notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load the dataset from your Google Drive (here, we stored it in a subfolder\n",
    "# called \"data\")\n",
    "titanic = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ef393a2",
   "metadata": {},
   "source": [
    "Let's take a look at the properties of the dataset we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3aad78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# How many  rows does the DataFrame have?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mtitanic\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# How many columns?\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(titanic\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# How many  rows does the DataFrame have?\n",
    "print(f\"Number of rows: {len(titanic)}\")\n",
    "# How many columns?\n",
    "print(f\"Number of columns: {len(titanic.columns)}\")\n",
    "# How many rows and columns, i.e. the shape\n",
    "print(f\"The shape of the Data Frame is: {titanic.shape}\")\n",
    "# General information about the DataFrame\n",
    "print(\"*\"*50)\n",
    "titanic.info()\n",
    "\n",
    "# Give the data type of each column.\n",
    "print(\"*\"*50)\n",
    "print(titanic.dtypes)\n",
    "\n",
    "# How many columns of each data type are there?\n",
    "#   Watch it! The book says to use get_dtype_counts(), but this method no longer exists\n",
    "print(\"*\"*50)\n",
    "print(titanic.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ec95c",
   "metadata": {},
   "source": [
    "## Indices\n",
    "\n",
    "The columns \"PassengerId\" is not an actual variabele, but contains a number to identify each observation. You can mark this column as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78d18a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtitanic\u001b[49m\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic.set_index(['PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3425b",
   "metadata": {},
   "source": [
    "## Qualitative variables\n",
    "\n",
    "Some of the variables, such as `Survived` and `Pclass`, are incorrectly considered to be quantitative. You can correct this by explicitly converting them to a **qualitative** (categorical) variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a192c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the variable Survived -> is considered to be quantitative\n",
    "print(titanic.Survived.describe())\n",
    "# Convert to a categorical variable\n",
    "titanic.Survived = titanic.Survived.astype('category')\n",
    "# Ask to describe once more -> now it is considered to be qualitative\n",
    "print(titanic.Survived.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96881d1",
   "metadata": {},
   "source": [
    "You can also mark variables as **ordinal**, that is, with an ordering. We will do this as an example with the variable \"Embarked\" and order the ports in the order of departure. The Titanic departed at SouthHampton, and then picked up passengers first at Cherbourg and then at Queenstown.\n",
    "\n",
    "For cases like this, define your own datatype specifying the order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2223ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.Embarked.unique())\n",
    "\n",
    "embarked_type = CategoricalDtype(categories=['S', 'C', 'Q'], ordered=True)\n",
    "titanic.Embarked = titanic.Embarked.astype(embarked_type)\n",
    "titanic.Embarked.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1808f375",
   "metadata": {},
   "source": [
    "This order will then always be respected, e.g. in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4af2da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mcountplot(data\u001b[38;5;241m=\u001b[39mtitanic, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.countplot(data=titanic, x='Embarked');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccfdf9",
   "metadata": {},
   "source": [
    "## Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22945701",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select all observations for a single variable (i.e. a DataFrame column)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtitanic\u001b[49m\u001b[38;5;241m.\u001b[39mAge\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This also works (and is prefarable as it will also work when the column name has a space in it):\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# titanic['Age']\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# This also works, but isn't very nice\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# titanic.loc[:, 'Age']\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# Select all observations for a single variable (i.e. a DataFrame column)\n",
    "titanic.Age\n",
    "# This also works (and is prefarable as it will also work when the column name has a space in it):\n",
    "# titanic['Age']\n",
    "# This also works, but isn't very nice\n",
    "# titanic.loc[:, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943d33b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select adjacent columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtitanic\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# Select adjacent columns\n",
    "titanic.iloc[:, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267f2d9",
   "metadata": {},
   "source": [
    "You can also select multiple columns based on their names.\n",
    "This is often clearer than selecting based on position and the columns must \n",
    "not be adjacent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3071015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtitanic\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;66;03m# Note: two sets of square brackets!\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic[['Name', 'Age', 'Cabin']] # Note: two sets of square brackets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef46fd5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Observation with row number 5 (counting from zero)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtitanic\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The first 4 observations\u001b[39;00m\n\u001b[0;32m      5\u001b[0m titanic\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# Observation with row number 5 (counting from zero)\n",
    "print(titanic.iloc[5])\n",
    "\n",
    "# The first 4 observations\n",
    "titanic.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f94a60f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select observations where the value of Age is less than 18\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtitanic\u001b[49m[titanic\u001b[38;5;241m.\u001b[39mAge \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m18\u001b[39m]  \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The same, but only keep the column 'Embarked'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m titanic[titanic\u001b[38;5;241m.\u001b[39mAge \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m18\u001b[39m]\u001b[38;5;241m.\u001b[39mEmbarked\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# Select observations where the value of Age is less than 18\n",
    "titanic[titanic.Age < 18]  \n",
    "\n",
    "# The same, but only keep the column 'Embarked'\n",
    "titanic[titanic.Age < 18].Embarked\n",
    "\n",
    "# The same, but keep columns 'Age' and 'Embarked'\n",
    "titanic[titanic['Age'] < 18][['Age', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f74c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all boys younger than 10\n",
    "titanic.query(\"(Sex=='male') and (Age < 18)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b425a",
   "metadata": {},
   "source": [
    "## Dropping Data and Working with Missing Data\n",
    "\n",
    "Pandas tries to make working with missing data as easy as possible. E.g., all of the descriptive statistics on pandas objects exclude missing data by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3c6e1",
   "metadata": {},
   "source": [
    "Let's starting by reading the titanic data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb502f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('https://raw.githubusercontent.com/DataRepo2019/Data-files/master/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc827a",
   "metadata": {},
   "source": [
    "The `PassengerId` column is identical to the index hence it doesn't provide any additional useful information. Let's drop this column (rather than setting it as the index as before). This can by done using `drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(\"PassengerId\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dd910",
   "metadata": {},
   "source": [
    "Notice that we actually didn't change the `titanic` `DataFrame`.  We can either assign the result of `drop` to a (new) `DataFrame`\n",
    "or we can use `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e010cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(3) # PassengerId is still here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(\"PassengerId\", axis=\"columns\")\n",
    "titanic.head(3) # PassengerId is now gone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d91b4b",
   "metadata": {},
   "source": [
    "From the output of the `info` method we can infer that certain columns contain many missing values, e.g. `Cabin` only contains 204 non-missing values. \n",
    "For the purposes of illustration, let's drop any row that has a missing observation by using \n",
    "the default behaviour of the `dropna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = titanic.dropna() # Drop any row that has at least one missing value\n",
    "print(cleaned.info())\n",
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a344447",
   "metadata": {},
   "source": [
    "This would only keep 183 values, which isn't a lot. We could also choose to drop only the rows that consist of nothing but missing values (there are no such rows in the `titanic` `DataFrame`), but here you can see how this would be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = titanic.dropna(how=\"all\")\n",
    "cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b75af0",
   "metadata": {},
   "source": [
    "Instead of relying on `info` to compute the number of non missing values we can also use the `isnull` and/or `notnull` methods.\n",
    "`notnull` computes a boolean `DataFrame` where an entry is `True` if and only if that entry is considered to be non missing in the original `DataFrame`. We can then use `sum` the compute the sum of each column. This gives the number of non missing values per column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_df = titanic.notnull()\n",
    "print(not_null_df.tail(3))\n",
    "print(\"Number of non null values in each column:\")\n",
    "print(not_null_df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4d0df",
   "metadata": {},
   "source": [
    "An even easier alternative is to simply use `count` on the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3606a9",
   "metadata": {},
   "source": [
    "The `Cabin` column has too many missing values, so probably isn't useful. For the `Age` column, we can *impute* the missing values, e.g. with the average age of all passengers. (We will see later what this means exactly). Let's do this using `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b356dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First compute the average age\n",
    "avg_age = titanic['Age'].mean()\n",
    "print(f\"(Rounded) Average age of passengers: {round(avg_age)}\")\n",
    "titanic = titanic.fillna(value={'Age' : avg_age})\n",
    "print(\"We should now confirm that the 'Age' column no longer has missing values\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e5ee4",
   "metadata": {},
   "source": [
    "## Creating New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb17e2b",
   "metadata": {},
   "source": [
    "We use a dataset containing $NO_2$ measurements in the the stations of Paris, Antwerp and London.\n",
    "\n",
    "Let's read the data and check whether it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/air_quality_no2.csv\"\n",
    "air_quality = pd.read_csv(URL)\n",
    "print(air_quality.info())\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453be401",
   "metadata": {},
   "source": [
    "We see that \n",
    "- the dates are stored as strings (object)\n",
    "- `datetime` is added as a column and we have a `RangeIndex`.\n",
    "\n",
    "We would like to\n",
    "- parse the dates, so that they are available as `datetime` objects\n",
    "- index the `DataFrame` rows by this date.\n",
    "\n",
    "This can be achieved by specifying the index column and by indicating that dates must be parsed on `read_csv`. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367332d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(URL, index_col=0, parse_dates=True)\n",
    "print(air_quality.info())\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e5401",
   "metadata": {},
   "source": [
    "We can clearly see the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d74337",
   "metadata": {},
   "source": [
    "### Creating a New Column Derived from (an) Existing Column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51741e",
   "metadata": {},
   "source": [
    "Assume we would like to express the concentration of the station in London in mg/m^3\n",
    "\n",
    "*(If we assume temperature of 25 degrees Celsius and pressure of 1013 hPa, the conversion factor is 1.882)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"london_mg_per_cubic\"] = air_quality[\"station_london\"] * 1.882\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844a838",
   "metadata": {},
   "source": [
    "To create a new column, use the `[]` brackets with the new column name at the left side of the assignment.  The computation is done **element wise**, hence there is no need for an explict loop!\n",
    "\n",
    "We can also use multiple columns to derive a new column.\n",
    "\n",
    "Let's check the ratio of the values in Paris versus Antwerp and save the result in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a38417",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"ratio_paris_antwerp\"] = air_quality[\"station_paris\"] / air_quality[\"station_antwerp\"]\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24c220",
   "metadata": {},
   "source": [
    "We can also perform more general mappings on columns, either using a function or a dictionary.\n",
    "\n",
    "Let's work with the Titanic data once more.  Let's say we want to numerically encode the `Sex` column, this can be done as follows. First let's check the unique values in the `Sex` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'male' : 0, 'female' : 1}\n",
    "titanic['Sex'] = titanic['Sex'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f427f9",
   "metadata": {},
   "source": [
    "Let's check whether it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a51ac",
   "metadata": {},
   "source": [
    "Let's add a new feature (i.e. a new column). When `Age` is less than 12 we will call this passenger a `child`, \n",
    "between 12 and 18 a `teen` and over 18 will be `adult`s.  First, we define a Python function implementing \n",
    "this mapping, and then we apply it to the `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_category(age):\n",
    "    if age < 12:\n",
    "        return \"child\"\n",
    "    if age < 18:\n",
    "        return \"teen\"\n",
    "    return \"adult\"\n",
    "\n",
    "titanic['AgeCategory'] = titanic['Age'].map(age_to_category)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83ed19",
   "metadata": {},
   "source": [
    "Here, we only scratched the surface of what is possible with pandas (and indeed, whole books have been written about pandas). In general the pandas getting started guide, the user guide and the API reference are very good resources to find additional information. You can find \n",
    "all of these [here](https://pandas.pydata.org/pandas-docs/stable/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
